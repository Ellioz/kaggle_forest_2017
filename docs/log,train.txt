
--- [START 2017-05-05 00:01:49] ----------------------------------------------------------------

** some experiment setting **
	SEED    = 123
	file    = /root/share/project/pytorch/build/forest-1/train-forest-0.py
	out_dir = /root/share/project/pytorch/results/kaggle-forest/new-xx05a

** dataset setting **
	(height,width)    = (64, 64)
	in_channels       = 3
	EXT               = jpg
	train_dataset.num = 40479
	test_dataset.num  = 3000
	batch_size = 96

** net setting **

SimpleNet64_2 (
  (layer0): Sequential (
    (0): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True)
    (2): PReLU (8)
    (3): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True)
    (5): PReLU (8)
    (6): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True)
    (8): PReLU (8)
  )
  (layer1): Sequential (
    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): PReLU (32)
    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (5): PReLU (32)
    (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (8): PReLU (32)
    (9): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (11): PReLU (32)
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (14): PReLU (32)
    (15): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  )
  (layer2): Sequential (
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): PReLU (32)
    (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (5): PReLU (32)
    (6): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (8): PReLU (32)
    (9): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (11): PReLU (32)
    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (14): PReLU (32)
    (15): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  )
  (layer3): Sequential (
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): PReLU (64)
    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (5): PReLU (64)
    (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (8): PReLU (64)
    (9): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (11): PReLU (64)
    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (14): PReLU (64)
    (15): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (16): Dropout (p = 0.25)
  )
  (layer4): Sequential (
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): PReLU (128)
    (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (5): PReLU (128)
    (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (8): PReLU (128)
    (9): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (11): PReLU (128)
    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (14): PReLU (128)
    (15): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (16): Dropout (p = 0.5)
  )
  (layer5): Sequential (
    (0): Linear (192 -> 512)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
    (3): Linear (512 -> 512)
    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)
    (5): ReLU (inplace)
  )
  (logit): Linear (512 -> 17)
)

** start training here! **
 epoch   iter   rate  |  smooth_loss  train_loss  (acc)  |  valid_loss    (acc)   | min
---------------------------------------------------------------------------------------
  1.0     421    0.1000   |  0.132  0.132  0.893 | 0.155  0.850  |  0.4 min 
  2.0     421    0.1000   |  0.121  0.121  0.883 | 0.128  0.882  |  0.4 min 
  3.0     421    0.1000   |  0.122  0.122  0.883 | 0.136  0.875  |  0.4 min 
  4.0     421    0.1000   |  0.133  0.133  0.881 | 0.155  0.855  |  0.4 min 
  5.0     421    0.1000   |  0.121  0.121  0.883 | 0.163  0.850  |  0.4 min 
  6.0     421    0.1000   |  0.132  0.132  0.877 | 0.144  0.869  |  0.4 min 
  7.0     421    0.1000   |  0.123  0.123  0.899 | 0.146  0.874  |  0.4 min 
  8.0     421    0.1000   |  0.122  0.122  0.900 | 0.117  0.900  |  0.4 min 
  9.0     421    0.1000   |  0.127  0.127  0.894 | 0.212  0.783  |  0.4 min 
 10.0     421    0.1000   |  0.117  0.117  0.904 | 0.176  0.818  |  0.4 min 
 11.0     421    0.1000   |  0.126  0.126  0.878 | 0.127  0.884  |  0.4 min 
 12.0     421    0.0500   |  0.082  0.082  0.940 | 0.108  0.906  |  0.4 min 
 13.0     421    0.0500   |  0.115  0.115  0.895 | 0.126  0.885  |  0.4 min 
 14.0     421    0.0500   |  0.132  0.132  0.872 | 0.151  0.860  |  0.4 min 
 15.0     421    0.0500   |  0.113  0.113  0.913 | 0.119  0.894  |  0.4 min 
 16.0     421    0.0500   |  0.118  0.118  0.896 | 0.106  0.905  |  0.4 min 
 17.0     421    0.0500   |  0.092  0.092  0.911 | 0.110  0.903  |  0.4 min 
 18.0     421    0.0500   |  0.130  0.130  0.887 | 0.387  0.596  |  0.4 min 
 19.0     421    0.0500   |  0.098  0.098  0.927 | 0.130  0.880  |  0.4 min 
 20.0     421    0.0500   |  0.132  0.132  0.875 | 0.191  0.815  |  0.4 min 
 21.0     421    0.0500   |  0.105  0.105  0.920 | 0.205  0.815  |  0.4 min 
 22.0     421    0.0100   |  0.111  0.111  0.909 | 0.094  0.920  |  0.4 min 
 23.0     421    0.0100   |  0.103  0.103  0.908 | 0.092  0.922  |  0.4 min 
 24.0     421    0.0100   |  0.101  0.101  0.909 | 0.092  0.921  |  0.4 min 
 25.0     421    0.0100   |  0.093  0.093  0.926 | 0.094  0.917  |  0.4 min 
 26.0     421    0.0100   |  0.108  0.108  0.910 | 0.095  0.919  |  0.4 min 
 27.0     421    0.0100   |  0.108  0.108  0.916 | 0.092  0.922  |  0.4 min 
 28.0     421    0.0100   |  0.085  0.085  0.930 | 0.100  0.914  |  0.4 min 
 29.0     421    0.0050   |  0.088  0.088  0.910 | 0.091  0.921  |  0.4 min 
 30.0     421    0.0050   |  0.100  0.100  0.900 | 0.089  0.925  |  0.4 min 
 31.0     421    0.0050   |  0.088  0.088  0.934 | 0.089  0.926  |  0.4 min 
 32.0     421    0.0050   |  0.101  0.101  0.911 | 0.090  0.926  |  0.4 min 
 33.0     421    0.0010   |  0.086  0.086  0.930 | 0.087  0.928  |  0.4 min 
 34.0     421    0.0010   |  0.090  0.090  0.928 | 0.087  0.927  |  0.4 min 
 35.0     421    0.0010   |  0.094  0.094  0.919 | 0.087  0.928  |  0.4 min 
 36.0     421    0.0010   |  0.081  0.081  0.939 | 0.087  0.927  |  0.4 min 
 37.0     421    0.0010   |  0.101  0.101  0.914 | 0.087  0.928  |  0.4 min 

/root/share/project/pytorch/results/kaggle-forest/new-xx05a/snap/final.torch:
	test_loss=0.086732, test_acc=0.927911, test_num=3000